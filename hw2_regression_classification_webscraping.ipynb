{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2018: Homework 02\n",
    "\n",
    "### Regression, Classification, Webscraping\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3), Alexander Fred-Ojala (Extra Credit)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction-classification, regression and web-scraping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file is uploaded to bCourses and is named: __Energy.csv__\n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1:Read the data file in python. Describe data features in terms of type, distribution range and mean values. Plot feature distributions.This step should give you clues about data sufficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1    float64\n",
      "X2    float64\n",
      "X3    float64\n",
      "X4    float64\n",
      "X5    float64\n",
      "X6      int64\n",
      "X7    float64\n",
      "X8      int64\n",
      "Y1    float64\n",
      "dtype: object\n",
      "               X1          X2          X3          X4         X5          X6  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.00000  768.000000   \n",
      "mean     0.764167  671.708333  318.500000  176.604167    5.25000    3.500000   \n",
      "std      0.105777   88.086116   43.626481   45.165950    1.75114    1.118763   \n",
      "min      0.620000  514.500000  245.000000  110.250000    3.50000    2.000000   \n",
      "25%      0.682500  606.375000  294.000000  140.875000    3.50000    2.750000   \n",
      "50%      0.750000  673.750000  318.500000  183.750000    5.25000    3.500000   \n",
      "75%      0.830000  741.125000  343.000000  220.500000    7.00000    4.250000   \n",
      "max      0.980000  808.500000  416.500000  220.500000    7.00000    5.000000   \n",
      "\n",
      "               X7         X8          Y1  \n",
      "count  768.000000  768.00000  768.000000  \n",
      "mean     0.234375    2.81250   22.307201  \n",
      "std      0.133221    1.55096   10.090196  \n",
      "min      0.000000    0.00000    6.010000  \n",
      "25%      0.100000    1.75000   12.992500  \n",
      "50%      0.250000    3.00000   18.950000  \n",
      "75%      0.400000    4.00000   31.667500  \n",
      "max      0.400000    5.00000   43.100000  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAJOCAYAAABFgJqNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJJRbJkiRJUolFsiRJklTy/wFzrg2Vs4gCmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfce8c1c6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data=pd.read_csv('Energy.csv')\n",
    "energydata=pd.DataFrame(data)\n",
    "print(energydata.dtypes)\n",
    "print(energydata.describe())\n",
    "energydata.hist(figsize=(12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __REGRESSION__:\n",
    "LABELS ARE CONTINUOUS VALUES.\n",
    "Here the model is trained to predict a continuous value for each instance.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a continuous value  for  that instance.  \n",
    "\n",
    "__Q2.1: Train a linear regression model on 85 percent of the given dataset, what is the intercept value and coefficient values.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total samples:  768\n",
      "Number of samples in training data: 652\n",
      "Number of samples in validation data: 116\n",
      "\n",
      "Coefficients:\n",
      "  [ -6.24938187e+01   1.14351200e+12  -1.14351200e+12  -2.28702401e+12\n",
      "   4.32184148e+00   1.94553204e-02   2.00676946e+01   2.36007105e-01]\n",
      "\n",
      "Intercept:  77.891702454\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "energy_x = energydata.iloc[:,:-1]\n",
    "energy_y = energydata['Y1']\n",
    "print('number of total samples: ',len(energy_x))\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(energy_x, energy_y, test_size=0.15, random_state = 100)\n",
    "print ('Number of samples in training data:',len(xtrain))\n",
    "print ('Number of samples in validation data:',len(xtest))\n",
    "\n",
    "reg=linear_model.LinearRegression(fit_intercept=True)\n",
    "reg.fit(xtrain, ytrain)\n",
    "\n",
    "ypred=reg.predict(xtest)\n",
    "ypred1=reg.predict(xtrain)\n",
    "\n",
    "print('\\nCoefficients:\\n ',reg.coef_)\n",
    "print('\\nIntercept: ',reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### Q.2.2: Report model performance using 'ROOT MEAN SQUARE' error metric on:  \n",
    "__1. Data that was used for training(Training error)__   \n",
    "__2. On the 15 percent of unseen data (test error) __ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. RMSE train data:  2.93551172582705\n",
      "2. RMSE test data:  2.885331133638931\n",
      "\n",
      "linear regression naccuracy (%):  90.9952525941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "print('1. RMSE train data: ',sqrt(mean_squared_error(ytrain, ypred1)))\n",
    "print('2. RMSE test data: ',sqrt(mean_squared_error(ytest, ypred)))\n",
    "acc_reglin=reg.score(xtest,ytest)\n",
    "print('\\nlinear regression naccuracy (%): ',acc_reglin*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__ Q2.3: Lets us see the effect of amount of data on the performance of prediction model.Use varying amounts of  Training data (100,200,300,400,500,all) to train regression models and report  training error and validation error in each case. Validation data/Test data   is the same as above for  all  these cases.__  \n",
    "\n",
    "Plot error rates vs number of training examples.Comment on the relationshipyou observe in the plot, between the amount of data used to train the model and the validation accuracy of the model.\n",
    "\n",
    "__Hint:__ Use array indexing to choose varying data amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 200, 300, 400, 500, 652]\n",
      "Number of samples in train data: 100\n",
      "Number of samples in test data: 116\n",
      "Training RMSE for 100 observations in training set: 2.92760482324\n",
      "Test RMSE for 100 observations in training set: 3.05435382389\n",
      "Number of samples in train data: 200\n",
      "Number of samples in test data: 116\n",
      "Training RMSE for 200 observations in training set: 2.94940507493\n",
      "Test RMSE for 200 observations in training set: 2.89522452089\n",
      "Number of samples in train data: 300\n",
      "Number of samples in test data: 116\n",
      "Training RMSE for 300 observations in training set: 3.03196105191\n",
      "Test RMSE for 300 observations in training set: 2.9246707638\n",
      "Number of samples in train data: 400\n",
      "Number of samples in test data: 116\n",
      "Training RMSE for 400 observations in training set: 2.93409921214\n",
      "Test RMSE for 400 observations in training set: 2.88615665111\n",
      "Number of samples in train data: 500\n",
      "Number of samples in test data: 116\n",
      "Training RMSE for 500 observations in training set: 3.00664352621\n",
      "Test RMSE for 500 observations in training set: 2.86352008296\n",
      "Number of samples in train data: 652\n",
      "Number of samples in test data: 116\n",
      "Training RMSE for all observations in training set: 2.93551172583\n",
      "Test RMSE for all observations in training set: 2.88533113364\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfce844ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Observations from the plot:\n",
      "1. Training RMSE wavers with increasing training observations.\n",
      "2. Test RMSE in general decreases with increasing observations in the training set.\n",
      "3. The training error being higher than test error means that the linear regression model accurately captures the trend in \n",
      "   the data. This can be seen in that the predictions made by this model on the test set are quite accurate and have low \n",
      "   errors/deviations from their actual values.\n",
      "4. The test and train RMSE values are very close to each other indicating a good model.\n"
     ]
    }
   ],
   "source": [
    "'''traindata=[100,200,300,400,500,652]\n",
    "\n",
    "n=[]\n",
    "ytesterror=[]\n",
    "ytrainerror=[]\n",
    "\n",
    "for i,x in enumerate(traindata):\n",
    "    xtrainpoints=xtrain[:x]\n",
    "    ytrainpoints=ytrain[:x]\n",
    "    n=np.append(n,x)\n",
    "    print('no of training points: ',int(n[i]))\n",
    "    print(len(xtrainpoints))\n",
    "    reg=linear_model.LinearRegression()\n",
    "    reg.fit(xtrainpoints, ytrainpoints)\n",
    "    \n",
    "    ypred=reg.predict(xtest)\n",
    "    ypred1=reg.predict(xtrainpoints)\n",
    "    \n",
    "    a=mean_squared_error(ytrainpoints, ypred1)\n",
    "    b=mean_squared_error(ytest, ypred)\n",
    "    \n",
    "    ytesterror=np.append(ytesterror,a)\n",
    "    ytrainerror=np.append(ytrainerror,b)\n",
    "    \n",
    "    print('\\n1.',x,'RMSE train data: ',a)\n",
    "    print('2.',x,'RMSE test data: ',b)\n",
    "\n",
    "plt.plot(n,ytesterror,n,ytrainerror)\n",
    "plt.xlabel('no of training samples')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.show()'''\n",
    "\n",
    "train_mse = list()\n",
    "test_mse = list()\n",
    "a = list([100,200,300,400,500,652])\n",
    "print(a)\n",
    "\n",
    "# Assuming error rate being talked about is RMSE and not error rate = 1 - accuracy\n",
    "\n",
    "# 100 samples\n",
    "# Splitting data \n",
    "x_train_100, x_test_100, y_train_100, y_test_100 = train_test_split(energy_x, energy_y, train_size = 100, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in train data:',len(x_train_100))\n",
    "print ('Number of samples in test data:',len(x_test_100))\n",
    "\n",
    "# Fitting the model\n",
    "LinearRegressionModel_100= linear_model.LinearRegression()\n",
    "LinearRegressionModel_100.fit(x_train_100, y_train_100)\n",
    "\n",
    "# RMSE for training data\n",
    "y_pred_train_100 = LinearRegressionModel_100.predict(x_train_100)\n",
    "train_mse_100 = np.sqrt(np.mean((y_train_100-y_pred_train_100)**2))\n",
    "print(\"Training RMSE for 100 observations in training set:\",train_mse_100)\n",
    "train_mse.append(train_mse_100)\n",
    "\n",
    "# RMSE for test data\n",
    "y_pred_test_100 = LinearRegressionModel_100.predict(x_test_100)\n",
    "test_mse_100 = np.sqrt(np.mean((y_test_100-y_pred_test_100)**2))\n",
    "print(\"Test RMSE for 100 observations in training set:\", test_mse_100)\n",
    "test_mse.append(test_mse_100)\n",
    "\n",
    "\n",
    "# 200 samples\n",
    "# Splitting data \n",
    "x_train_200, x_test_200, y_train_200, y_test_200 = train_test_split(energy_x, energy_y, train_size = 200, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in train data:',len(x_train_200))\n",
    "print ('Number of samples in test data:',len(x_test_200))\n",
    "\n",
    "# Fitting the model\n",
    "LinearRegressionModel_200= linear_model.LinearRegression()\n",
    "LinearRegressionModel_200.fit(x_train_200, y_train_200)\n",
    "\n",
    "# RMSE for training data\n",
    "y_pred_train_200 = LinearRegressionModel_200.predict(x_train_200)\n",
    "train_mse_200 = np.sqrt(np.mean((y_train_200-y_pred_train_200)**2))\n",
    "print(\"Training RMSE for 200 observations in training set:\",train_mse_200)\n",
    "train_mse.append(train_mse_200)\n",
    "\n",
    "# RMSE for test data\n",
    "y_pred_test_200 = LinearRegressionModel_200.predict(x_test_200)\n",
    "test_mse_200 = np.sqrt(np.mean((y_test_200-y_pred_test_200)**2))\n",
    "print(\"Test RMSE for 200 observations in training set:\", test_mse_200)\n",
    "test_mse.append(test_mse_200)\n",
    "\n",
    "\n",
    "# 300 samples\n",
    "# Splitting data \n",
    "x_train_300, x_test_300, y_train_300, y_test_300 = train_test_split(energy_x, energy_y, train_size = 300, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in train data:',len(x_train_300))\n",
    "print ('Number of samples in test data:',len(x_test_300))\n",
    "\n",
    "# Fitting the model\n",
    "LinearRegressionModel_300= linear_model.LinearRegression()\n",
    "LinearRegressionModel_300.fit(x_train_300, y_train_300)\n",
    "\n",
    "# RMSE for training data\n",
    "y_pred_train_300 = LinearRegressionModel_300.predict(x_train_300)\n",
    "train_mse_300 = np.sqrt(np.mean((y_train_300-y_pred_train_300)**2))\n",
    "print(\"Training RMSE for 300 observations in training set:\",train_mse_300)\n",
    "train_mse.append(train_mse_300)\n",
    "\n",
    "# RMSE for test data\n",
    "y_pred_test_300 = LinearRegressionModel_300.predict(x_test_300)\n",
    "test_mse_300 = np.sqrt(np.mean((y_test_300-y_pred_test_300)**2))\n",
    "print(\"Test RMSE for 300 observations in training set:\", test_mse_300)\n",
    "test_mse.append(test_mse_300)\n",
    "\n",
    "\n",
    "# 400 samples\n",
    "# Splitting data \n",
    "x_train_400, x_test_400, y_train_400, y_test_400 = train_test_split(energy_x, energy_y, train_size = 400, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in train data:',len(x_train_400))\n",
    "print ('Number of samples in test data:',len(x_test_400))\n",
    "\n",
    "# Fitting the model\n",
    "LinearRegressionModel_400= linear_model.LinearRegression()\n",
    "LinearRegressionModel_400.fit(x_train_400, y_train_400)\n",
    "\n",
    "# RMSE for training data\n",
    "y_pred_train_400 = LinearRegressionModel_400.predict(x_train_400)\n",
    "train_mse_400 = np.sqrt(np.mean((y_train_400-y_pred_train_400)**2))\n",
    "print(\"Training RMSE for 400 observations in training set:\",train_mse_400)\n",
    "train_mse.append(train_mse_400)\n",
    "\n",
    "# RMSE for test data\n",
    "y_pred_test_400 = LinearRegressionModel_400.predict(x_test_400)\n",
    "test_mse_400 = np.sqrt(np.mean((y_test_400-y_pred_test_400)**2))\n",
    "print(\"Test RMSE for 400 observations in training set:\", test_mse_400)\n",
    "test_mse.append(test_mse_400)\n",
    "\n",
    "\n",
    "# 500 samples\n",
    "# Splitting data \n",
    "x_train_500, x_test_500, y_train_500, y_test_500 = train_test_split(energy_x, energy_y, train_size = 500, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in train data:',len(x_train_500))\n",
    "print ('Number of samples in test data:',len(x_test_500))\n",
    "\n",
    "# Fitting the model\n",
    "LinearRegressionModel_500= linear_model.LinearRegression()\n",
    "LinearRegressionModel_500.fit(x_train_500, y_train_500)\n",
    "\n",
    "# RMSE for training data\n",
    "y_pred_train_500 = LinearRegressionModel_500.predict(x_train_500)\n",
    "train_mse_500 = np.sqrt(np.mean((y_train_500-y_pred_train_500)**2))\n",
    "print(\"Training RMSE for 500 observations in training set:\",train_mse_500)\n",
    "train_mse.append(train_mse_500)\n",
    "\n",
    "# RMSE for test data\n",
    "y_pred_test_500 = LinearRegressionModel_500.predict(x_test_500)\n",
    "test_mse_500 = np.sqrt(np.mean((y_test_500-y_pred_test_500)**2))\n",
    "print(\"Test RMSE for 500 observations in training set:\", test_mse_500)\n",
    "test_mse.append(test_mse_500)\n",
    "\n",
    "# All samples\n",
    "# Splitting data \n",
    "x_train_all, x_test_all, y_train_all, y_test_all = train_test_split(energy_x, energy_y, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in train data:',len(x_train_all))\n",
    "print ('Number of samples in test data:',len(x_test_all))\n",
    "\n",
    "# Fitting the model\n",
    "LinearRegressionModel_all= linear_model.LinearRegression()\n",
    "LinearRegressionModel_all.fit(x_train_all, y_train_all)\n",
    "\n",
    "# RMSE for training data\n",
    "y_pred_train_all = LinearRegressionModel_all.predict(x_train_all)\n",
    "train_mse_all = np.sqrt(np.mean((y_train_all-y_pred_train_all)**2))\n",
    "print(\"Training RMSE for all observations in training set:\",train_mse_all)\n",
    "train_mse.append(train_mse_all)\n",
    "\n",
    "# RMSE for test data\n",
    "y_pred_test_all = LinearRegressionModel_all.predict(x_test_all)\n",
    "test_mse_all = np.sqrt(np.mean((y_test_all-y_pred_test_all)**2))\n",
    "print(\"Test RMSE for all observations in training set:\", test_mse_all)\n",
    "test_mse.append(test_mse_all)\n",
    "\n",
    "plt.plot(a,train_mse, label = 'train RMSE')\n",
    "plt.plot(a,test_mse, label = \"test RMSE\");\n",
    "#plt.legend(loc=3)\n",
    "plt.xlabel(\"Number of samples in the test set\")\n",
    "plt.ylabel(\"Training/Test RMSE\")\n",
    "plt.show()\n",
    "\n",
    "print('''\\n\\nObservations from the plot:\n",
    "1. Training RMSE wavers with increasing training observations.\n",
    "2. Test RMSE in general decreases with increasing observations in the training set.\n",
    "3. The training error being higher than test error means that the linear regression model accurately captures the trend in \n",
    "   the data. This can be seen in that the predictions made by this model on the test set are quite accurate and have low \n",
    "   errors/deviations from their actual values.\n",
    "4. The test and train RMSE values are very close to each other indicating a good model.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import numpy as np\\n#np.random.seed(100)\\n\\nxtrain1=xtrain[:100]            # error becomes very large when I choose random samples - xtrain.sample(100). why??\\nxtrain2=xtrain[:200]\\nxtrain3=xtrain[:300]\\nxtrain4=xtrain[:400]\\nxtrain5=xtrain[:500]\\nytrain1=ytrain[:100]\\nytrain2=ytrain[:200]\\nytrain3=ytrain[:300]\\nytrain4=ytrain[:400]\\nytrain5=ytrain[:500]\\nprint(xtrain1.head())\\nprint(xtrain2.head())\\n\\nreg1=linear_model.LinearRegression()\\nreg1.fit(xtrain1, ytrain1)\\n\\nypred1=reg1.predict(xtest)\\nypred11=reg1.predict(xtrain1)\\n\\nprint('1. 100 RMSE train data: ',sqrt(mean_squared_error(ytrain1, ypred11)))\\nprint('2. 100 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred1)))\\n\\nreg2=linear_model.LinearRegression()\\nreg.fit(xtrain2, ytrain2)\\n\\nypred2=reg.predict(xtest)\\nypred12=reg.predict(xtrain2)\\n\\nprint('\\n1. 200 RMSE train data: ',sqrt(mean_squared_error(ytrain2, ypred12)))\\nprint('2. 200 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred2)))\\n\\nreg3=linear_model.LinearRegression()\\nreg.fit(xtrain3, ytrain3)\\n\\nypred3=reg.predict(xtest)\\nypred13=reg.predict(xtrain3)\\n\\nprint('\\n1. 300 RMSE train data: ',sqrt(mean_squared_error(ytrain3, ypred13))\\nprint('2. 300 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred3)))\\n\\nreg4=linear_model.LinearRegression()\\nreg.fit(xtrain4, ytrain4)\\n\\nypred4=reg.predict(xtest)\\nypred14=reg.predict(xtrain4)\\n\\nprint('\\n1. 400 RMSE train data: ',sqrt(mean_squared_error(ytrain4, ypred14)))\\nprint('2. 400 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred4)))\\n\\nreg5=linear_model.LinearRegression()\\nreg.fit(xtrain5, ytrain5)\\n\\nypred5=reg.predict(xtest)\\nypred15=reg.predict(xtrain5)\\n\\nprint('\\n1. 500 RMSE train data: ',sqrt(mean_squared_error(ytrain5, ypred15)))\\nprint('2. 500 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred5)))\\n\\nprint('\\nerror for all data is same as in previous part')\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IGNORE\n",
    "\n",
    "'''import numpy as np\n",
    "#np.random.seed(100)\n",
    "\n",
    "xtrain1=xtrain[:100]            # error becomes very large when I choose random samples - xtrain.sample(100). why??\n",
    "xtrain2=xtrain[:200]\n",
    "xtrain3=xtrain[:300]\n",
    "xtrain4=xtrain[:400]\n",
    "xtrain5=xtrain[:500]\n",
    "ytrain1=ytrain[:100]\n",
    "ytrain2=ytrain[:200]\n",
    "ytrain3=ytrain[:300]\n",
    "ytrain4=ytrain[:400]\n",
    "ytrain5=ytrain[:500]\n",
    "print(xtrain1.head())\n",
    "print(xtrain2.head())\n",
    "\n",
    "reg1=linear_model.LinearRegression()\n",
    "reg1.fit(xtrain1, ytrain1)\n",
    "\n",
    "ypred1=reg1.predict(xtest)\n",
    "ypred11=reg1.predict(xtrain1)\n",
    "\n",
    "print('1. 100 RMSE train data: ',sqrt(mean_squared_error(ytrain1, ypred11)))\n",
    "print('2. 100 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred1)))\n",
    "\n",
    "reg2=linear_model.LinearRegression()\n",
    "reg.fit(xtrain2, ytrain2)\n",
    "\n",
    "ypred2=reg.predict(xtest)\n",
    "ypred12=reg.predict(xtrain2)\n",
    "\n",
    "print('\\n1. 200 RMSE train data: ',sqrt(mean_squared_error(ytrain2, ypred12)))\n",
    "print('2. 200 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred2)))\n",
    "\n",
    "reg3=linear_model.LinearRegression()\n",
    "reg.fit(xtrain3, ytrain3)\n",
    "\n",
    "ypred3=reg.predict(xtest)\n",
    "ypred13=reg.predict(xtrain3)\n",
    "\n",
    "print('\\n1. 300 RMSE train data: ',sqrt(mean_squared_error(ytrain3, ypred13))\n",
    "print('2. 300 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred3)))\n",
    "\n",
    "reg4=linear_model.LinearRegression()\n",
    "reg.fit(xtrain4, ytrain4)\n",
    "\n",
    "ypred4=reg.predict(xtest)\n",
    "ypred14=reg.predict(xtrain4)\n",
    "\n",
    "print('\\n1. 400 RMSE train data: ',sqrt(mean_squared_error(ytrain4, ypred14)))\n",
    "print('2. 400 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred4)))\n",
    "\n",
    "reg5=linear_model.LinearRegression()\n",
    "reg.fit(xtrain5, ytrain5)\n",
    "\n",
    "ypred5=reg.predict(xtest)\n",
    "ypred15=reg.predict(xtrain5)\n",
    "\n",
    "print('\\n1. 500 RMSE train data: ',sqrt(mean_squared_error(ytrain5, ypred15)))\n",
    "print('2. 500 RMSE test data: ',sqrt(mean_squared_error(ytest, ypred5)))\n",
    "\n",
    "print('\\nerror for all data is same as in previous part')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__CLASSIFICATION__:\n",
    "LABELS ARE DISCRETE VALUES.\n",
    "Here the model is trained to classify each instance into a set of predefined  discrete classes.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a  class of that instance. You can also output the probabilities of an instance belnging to a class.  \n",
    "\n",
    "__ Q 3.1:  Bucket values of 'y1' i.e 'Heating Load'  from the original dataset into 3 classes:__ \n",
    "\n",
    "0: 'Low' ( < 15),   \n",
    "1: 'Medium'  (15-30),   \n",
    "2: 'High'  (>30)\n",
    "\n",
    "This converts the given dataset  into a classification problem, classes being, Heating load is: *low, medium or high*. Use this datset with transformed 'heating load' for creating a  logistic regression classifiction model that predicts heating load type of a building. Use test-train split ratio of 0.15.  \n",
    "\n",
    "*Report training and test accuracies and  confusion matrices.*\n",
    "\n",
    "\n",
    "**HINT:** Use pandas.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Heating Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8 Heating Load\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0       Medium\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0       Medium\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0       Medium\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0       Medium\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0       Medium"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energydata['Heating Load']=pd.cut(energydata['Y1'],bins=[0,15,30,45],labels=['Low','Medium','High'])\n",
    "energydata=energydata.drop('Y1',axis=1)\n",
    "energydata.head()       #energydata['Heating Load'].unique to chech values of bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy for train data:  0.773006134969 and for test data:  0.76724137931\n",
      "Confusion matrix of train data is: \n",
      "           Predicted 0  Predicted 1  Predicted 2\n",
      "Actual 0          244            1            0\n",
      "Actual 1           71          120           41\n",
      "Actual 2            0           35          140\n",
      "Confusion matrix of test data is: \n",
      "           Predicted 0  Predicted 1  Predicted 2\n",
      "Actual 0           40            0            0\n",
      "Actual 1           12           29            9\n",
      "Actual 2            0            6           20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "energy1x=energydata.iloc[:,:-1]\n",
    "energy1y=energydata['Heating Load'].map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(energy1x, energy1y, test_size=0.15, random_state = 100)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(xtrain,ytrain)\n",
    "Ypred=logreg.predict(xtest)\n",
    "acc_train=logreg.score(xtrain,ytrain)\n",
    "acc_test=logreg.score(xtest,ytest)\n",
    "print('Logistic Regression accuracy for train data: ',acc_train,'and for test data: ',acc_test)\n",
    "\n",
    "#acc_log = sum(Ypred == ytest)/len(ytest)*100\n",
    "#print('Scikit Model score: ',acc_log)\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true_train=ytrain\n",
    "y_pred_train=logreg.predict(xtrain)\n",
    "ConfusionMatrix=pd.DataFrame(confusion_matrix(y_true_train, y_pred_train), \\\n",
    "                             columns=['Predicted 0','Predicted 1','Predicted 2'],index=['Actual 0','Actual 1','Actual 2'])\n",
    "print ('Confusion matrix of train data is: \\n',ConfusionMatrix)\n",
    "\n",
    "y_true_test=ytest\n",
    "y_pred_test=logreg.predict(xtest)\n",
    "ConfusionMatrix1=pd.DataFrame(confusion_matrix(y_true_test, y_pred_test), \\\n",
    "                             columns=['Predicted 0','Predicted 1','Predicted 2'],index=['Actual 0','Actual 1','Actual 2'])\n",
    "print ('Confusion matrix of test data is: \\n',ConfusionMatrix1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Q2.2: One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. This makes training less sensitive to the scale of features . Scaling is important in algorithms that use distance based classification, SVM or K means or involve gradient descent optimization.If we  Scale features in the range [0,1] it is called unity based normalization.__\n",
    "\n",
    "__Perform unity based normalization on the above dataset and train the model again, compare model performance in training and validation with your previous model.__  \n",
    "\n",
    "refer:http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "more at: https://en.wikipedia.org/wiki/Feature_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "\n",
      " Sample row from actual train values:\n",
      "        X1     X2     X3     X4   X5  X6    X7  X8\n",
      "458  0.74  686.0  245.0  220.5  3.5   4  0.25   4\n",
      "\n",
      " Scaled values of the same row:\n",
      " [[ 0.33333333  0.58333333  0.          1.          0.          0.66666667\n",
      "   0.625       0.8       ]]\n",
      "\n",
      " Sample row from actual test values:\n",
      "        X1     X2     X3     X4   X5  X6   X7  X8\n",
      "173  0.71  710.5  269.5  220.5  3.5   3  0.1   3\n",
      "\n",
      " Scaled values of the test values\n",
      " [[ 0.25        0.66666667  0.14285714  1.          0.          0.33333333\n",
      "   0.25        0.6       ]]\n",
      "Training accuracy for scaled features: 0.799079754601\n",
      "Accuracy of the model on test data:  0.784482758621\n",
      "\n",
      "model improves after scaling\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()    \n",
    "print(min_max_scaler)\n",
    "\n",
    "energy_x = energydata.iloc[:,:-1]\n",
    "energy_y = energydata['Heating Load'].map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(energy_x, energy_y, test_size=0.15, random_state = 100)\n",
    "\n",
    "x_train_scaled = min_max_scaler.fit_transform(xtrain)\n",
    "x_test_scaled = min_max_scaler.fit_transform(xtest)\n",
    "\n",
    "print(\"\\n Sample row from actual train values:\\n\", xtrain[0:1][:])\n",
    "print(\"\\n Scaled values of the same row:\\n\", x_train_scaled[0:1][:])\n",
    "print(\"\\n Sample row from actual test values:\\n\", xtest[0:1][:])\n",
    "print(\"\\n Scaled values of the test values\\n\", x_test_scaled[0:1][:])\n",
    "\n",
    "Logreg_scaled = linear_model.LogisticRegression()\n",
    "Logreg_scaled.fit(x_train_scaled, ytrain)\n",
    "\n",
    "training_accuracy_scaled=Logreg_scaled.score(x_train_scaled,ytrain)\n",
    "print ('Training accuracy for scaled features:',training_accuracy_scaled)\n",
    "\n",
    "test_accuracy_scaled=Logreg_scaled.score(x_test_scaled,ytest)\n",
    "print('Accuracy of the model on test data: ',test_accuracy_scaled)\n",
    "print('\\nmodel improves after scaling')\n",
    "#minmax=MinMaxScaler().fit(xtrain)\n",
    "#scaled_xtrain=minmax.transform(xtrain)\n",
    "#scaled_ytrain=minmax.fit_transform(ytrain.values.reshape(-1,1))\n",
    "#scaled_xtest=minmax.transform(xtest)\n",
    "#scaled_ytest=minmax.fit_transform(ytest.values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__ 1. Read __`diabetesdata.csv`__ file into a pandas dataframe. Analyze the data features, check for NaN values. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "__ 2. Preprocess data to replace NaN values in a feature(if any) using mean of the feature.  \n",
    "Train  logistic regression, SVM, perceptron, kNN, xgboost and random forest models using this preprocessed data with 20% test split.Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree        Age  \\\n",
      "0              6    148.000000  72        0  33.6     0.627  50.000000   \n",
      "1              1    121.016349  66        0  26.6     0.351  31.000000   \n",
      "2              8    183.000000  64        0  23.3     0.672  33.353741   \n",
      "3              1    121.016349  66       94  28.1     0.167  21.000000   \n",
      "4              0    137.000000  40      168  43.1     2.288  33.000000   \n",
      "\n",
      "   IsDiabetic  \n",
      "0           1  \n",
      "1           0  \n",
      "2           1  \n",
      "3           0  \n",
      "4           1  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAJOCAYAAAB4CERfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfce6c6f6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=pd.read_csv('diabetesdata.csv')\n",
    "diabetes=pd.DataFrame(data)\n",
    "diabetes1=diabetes.fillna(diabetes.mean())\n",
    "print(diabetes1.head())\n",
    "diabetes1.hist(figsize=(8,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes_x=diabetes1.iloc[:,:-1]\n",
    "diabetes_y=diabetes['IsDiabetic']\n",
    "#diabetes_y=diabetes_y.to_frame('IsDiabetic')\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(diabetes_x,diabetes_y,test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of correct predictions:  113 / 154\n",
      "Logistic Regression Accuracy for test data:  73.0 % and fo rtrain data:  78.0\n"
     ]
    }
   ],
   "source": [
    "#  LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(xtrain,ytrain)\n",
    "ypred=logreg.predict(xtest)\n",
    "print('no. of correct predictions: ',sum(ypred==ytest),'/',len(xtest))\n",
    "trainacc=logreg.score(xtrain,ytrain)\n",
    "accuracy=logreg.score(xtest,ytest)\n",
    "print('Logistic Regression Accuracy for test data: ',str(round(accuracy,2)*100),'% and fo rtrain data: ',str(round(trainacc,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of correct predictions:  101 / 154\n",
      "Logistic Regression Accuracy for test data:  66.0 % and fo rtrain data:  100.0\n"
     ]
    }
   ],
   "source": [
    "#  SVM\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "svc=SVC()\n",
    "svc.fit(xtrain,ytrain)\n",
    "ypred=svc.predict(xtest)\n",
    "print('no. of correct predictions: ',sum(ypred==ytest),'/',len(xtest))\n",
    "trainacc=svc.score(xtrain,ytrain)\n",
    "accuracy=svc.score(xtest,ytest)\n",
    "print('Logistic Regression Accuracy for test data: ',str(round(accuracy,2)*100),'% and fo rtrain data: ',str(round(trainacc,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of correct predictions:  99 / 154\n",
      "Logistic Regression Accuracy for test data:  64.0 % and fo rtrain data:  64.0\n"
     ]
    }
   ],
   "source": [
    "#  PERCEPTRON\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "per=Perceptron()\n",
    "per.fit(xtrain,ytrain)\n",
    "ypred=per.predict(xtest)\n",
    "print('no. of correct predictions: ',sum(ypred==ytest),'/',len(xtest))\n",
    "trainacc=per.score(xtrain,ytrain)\n",
    "accuracy=per.score(xtest,ytest)\n",
    "print('Logistic Regression Accuracy for test data: ',str(round(accuracy,2)*100),'% and fo rtrain data: ',str(round(trainacc,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of correct predictions:  110 / 154\n",
      "Logistic Regression Accuracy for test data:  71.0 % and fo rtrain data:  85.0\n"
     ]
    }
   ],
   "source": [
    "#  KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(xtrain,ytrain)\n",
    "ypred=knn.predict(xtest)\n",
    "print('no. of correct predictions: ',sum(ypred==ytest),'/',len(xtest))\n",
    "trainacc=knn.score(xtrain,ytrain)\n",
    "accuracy=knn.score(xtest,ytest)\n",
    "print('Logistic Regression Accuracy for test data: ',str(round(accuracy,2)*100),'% and fo rtrain data: ',str(round(trainacc,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of correct predictions:  111 / 154\n",
      "Logistic Regression Accuracy for test data:  72.0 % and fo rtrain data:  100.0\n"
     ]
    }
   ],
   "source": [
    "#  XGBOOST\n",
    "\n",
    "import xgboost as xgb\n",
    "gradboost=xgb.XGBClassifier(n_estimators=1000)\n",
    "gradboost.fit(xtrain,ytrain)\n",
    "ypred=gradboost.predict(xtest)\n",
    "print('no. of correct predictions: ',sum(ypred==ytest),'/',len(xtest))\n",
    "trainacc=gradboost.score(xtrain,ytrain)\n",
    "accuracy=gradboost.score(xtest,ytest)\n",
    "print('Logistic Regression Accuracy for test data: ',str(round(accuracy,2)*100),'% and fo rtrain data: ',str(round(trainacc,2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of correct predictions:  108 / 154\n",
      "Logistic Regression Accuracy for test data:  70.0 % and fo rtrain data:  100.0\n"
     ]
    }
   ],
   "source": [
    "#  RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(xtrain,ytrain)\n",
    "ypred=rf.predict(xtest)\n",
    "print('no. of correct predictions: ',sum(ypred==ytest),'/',len(xtest))\n",
    "trainacc=rf.score(xtrain,ytrain)\n",
    "accuracy=rf.score(xtest,ytest)\n",
    "print('Logistic Regression Accuracy for test data: ',str(round(accuracy,2)*100),'% and fo rtrain data: ',str(round(trainacc,2)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__3. What is the  ratio of diabetic persons in 3 equirange bands of 'BMI' and 'Pedigree' in the provided dataset.__\n",
    "\n",
    " __Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsDiabetic    0    1\n",
      "BMI_cat             \n",
      "0            49    2\n",
      "1           437  244\n",
      "2            14   22\n",
      "IsDiabetic      0    1\n",
      "Pedigree_cat          \n",
      "0             461  224\n",
      "1              34   40\n",
      "2               5    4\n",
      "IsDiabetic    0    1  Ratio of diabetics by BMI\n",
      "BMI_cat                                        \n",
      "0            49    2                   0.007463\n",
      "1           437  244                   0.910448\n",
      "2            14   22                   0.082090\n",
      "IsDiabetic      0    1  Ratio of diabetics by Pedigree\n",
      "Pedigree_cat                                          \n",
      "0             461  224                        0.835821\n",
      "1              34   40                        0.149254\n",
      "2               5    4                        0.014925\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratio of diabetics by BMI</th>\n",
       "      <th>Ratio of diabetics by Pedigree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007463</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.149254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratio of diabetics by BMI  Ratio of diabetics by Pedigree\n",
       "0                   0.007463                        0.835821\n",
       "1                   0.910448                        0.149254\n",
       "2                   0.082090                        0.014925"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BP = pd.cut(diabetes[\"BP\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"]) \n",
    "X_BP=X_BP.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes['BP_cat'] = X_BP\n",
    "\n",
    "X_insulin = pd.cut(diabetes[\"insulin\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"])\n",
    "X_insulin=X_insulin.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes['insulin_cat'] = X_insulin\n",
    "\n",
    "X_BMI = pd.cut(diabetes[\"BMI\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"])\n",
    "X_BMI=X_BMI.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes['BMI_cat'] = X_BMI\n",
    "\n",
    "X_Pedigree = pd.cut(diabetes[\"Pedigree\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"])\n",
    "X_Pedigree=X_Pedigree.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes['Pedigree_cat'] = X_Pedigree\n",
    "\n",
    "tab1 = pd.crosstab(diabetes[\"BMI_cat\"], diabetes[\"IsDiabetic\"])\n",
    "print(tab1)\n",
    "tab2 = pd.crosstab(diabetes[\"Pedigree_cat\"],diabetes[\"IsDiabetic\"])\n",
    "print(tab2)\n",
    "ratio1 = pd.Series([2/268, 244/268, 22/268]) \n",
    "tab1[\"Ratio of diabetics by BMI\"]=ratio1\n",
    "print(tab1)\n",
    "ratio2 = pd.Series([224/268, 40/268, 4/268])\n",
    "tab2[\"Ratio of diabetics by Pedigree\"] = ratio2\n",
    "print(tab2)\n",
    "ratio_df = pd.concat([tab1[\"Ratio of diabetics by BMI\"],tab2[\"Ratio of diabetics by Pedigree\"]], axis = 1)\n",
    "\n",
    "ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__4. Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group.We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  IsDiabetic\n",
      "0              6         148.0  72        0  33.6     0.627  50.0           1\n",
      "1              1           NaN  66        0  26.6     0.351  31.0           0\n",
      "2              8         183.0  64        0  23.3     0.672   NaN           1\n",
      "3              1           NaN  66       94  28.1     0.167  21.0           0\n",
      "4              0         137.0  40      168  43.1     2.288  33.0           1\n",
      "\n",
      " TimesPregnant     0\n",
      "glucoseLevel     34\n",
      "BP                0\n",
      "insulin           0\n",
      "BMI               0\n",
      "Pedigree          0\n",
      "Age              33\n",
      "IsDiabetic        0\n",
      "dtype: int64\n",
      "\n",
      " [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Guess_Age table:\n",
      " [[24 29 33]\n",
      " [25 29 32]\n",
      " [55 37 31]]\n",
      "\n",
      "Assigning age values to NAN age values in the dataset...\n",
      "\n",
      "\n",
      " [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Guess_Glucose table:\n",
      " [[115 112 133]\n",
      " [127 115 129]\n",
      " [137 149 159]]\n",
      "\n",
      "Assigning glucose values to NAN age values in the dataset...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "      <th>BP_cat</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>Pedigree_cat</th>\n",
       "      <th>insulin_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree  Age  IsDiabetic  \\\n",
       "0              6           148  72        0  33.6     0.627   50           1   \n",
       "1              1           112  66        0  26.6     0.351   31           0   \n",
       "2              8           183  64        0  23.3     0.672   29           1   \n",
       "3              1           112  66       94  28.1     0.167   21           0   \n",
       "4              0           137  40      168  43.1     2.288   33           1   \n",
       "\n",
       "   BP_cat  BMI_cat  Pedigree_cat  insulin_cat  \n",
       "0       1        1             0            0  \n",
       "1       1        1             0            0  \n",
       "2       1        1             0            0  \n",
       "3       1        1             0            0  \n",
       "4       0        1             2            0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data as a new file\n",
    "diabetes2 = pd.read_csv(\"diabetesdata.csv\")\n",
    "print(diabetes2.head())\n",
    "print(\"\\n\",diabetes2.isnull().sum())\n",
    "\n",
    "# Converting features to categorical variables\n",
    "X_BP = pd.cut(diabetes2[\"BP\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"]) \n",
    "X_BP=X_BP.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes2['BP_cat'] = X_BP\n",
    "\n",
    "X_BMI = pd.cut(diabetes2[\"BMI\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"])\n",
    "X_BMI=X_BMI.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes2['BMI_cat'] = X_BMI\n",
    "\n",
    "X_Pedigree = pd.cut(diabetes2[\"Pedigree\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"])\n",
    "X_Pedigree=X_Pedigree.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes2['Pedigree_cat'] = X_Pedigree\n",
    "\n",
    "X_insulin = pd.cut(diabetes2[\"insulin\"],bins=3,labels = [\"Low\", \"Medium\", \"High\"])\n",
    "X_insulin=X_insulin.map({'Low': 0, 'Medium': 1,'High' :2})\n",
    "diabetes2['insulin_cat'] = X_insulin\n",
    "\n",
    "# Initiating our age guess table\n",
    "guess_ages = np.zeros((3,3),dtype=int)\n",
    "print(\"\\n\",guess_ages)\n",
    "\n",
    "# Forming the age guess table and modifying the diabetes2 dataframe to fill median values\n",
    "for i in range(0, 3):\n",
    "        for j in range(0,3):\n",
    "            guess_df = diabetes2[(diabetes2['BP_cat'] == i) \\\n",
    "                        &(diabetes2['BMI_cat'] == j)]['Age'].dropna()\n",
    "\n",
    "            # Extract the median age for this group\n",
    "            # (less sensitive) to outliers\n",
    "            age_guess = guess_df.median()\n",
    "          \n",
    "            # Convert random age float to int\n",
    "            guess_ages[i,j] = int(age_guess)\n",
    "    \n",
    "            \n",
    "print('Guess_Age table:\\n',guess_ages)\n",
    "print ('\\nAssigning age values to NAN age values in the dataset...')\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    for j in range(0, 3):\n",
    "        diabetes2.loc[ (diabetes2.Age.isnull()) & (diabetes2.BP_cat == i) \\\n",
    "                    & (diabetes.BMI_cat == j),'Age'] = guess_ages[i,j]\n",
    "                    \n",
    "\n",
    "diabetes2['Age'] = diabetes2['Age'].astype(int)\n",
    "print()\n",
    "\n",
    "# Initiating our glucose guess table\n",
    "guess_glucose = np.zeros((3,3),dtype=int)\n",
    "print(\"\\n\",guess_glucose)\n",
    "\n",
    "# Forming the glucose guess table and modifying the diabetes2 dataframe to fill median values\n",
    "for i in range(0, 3):\n",
    "        for j in range(0,3):\n",
    "            guess_df2 = diabetes2[(diabetes2['Pedigree_cat'] == i) \\\n",
    "                        &(diabetes2['BP_cat'] == j)]['glucoseLevel'].dropna()\n",
    "\n",
    "            # Extract the median age for this group\n",
    "            # (less sensitive) to outliers\n",
    "            glucose_guess = guess_df2.median()\n",
    "          \n",
    "            # Convert random age float to int\n",
    "            guess_glucose[i,j] = int(glucose_guess)\n",
    "    \n",
    "            \n",
    "print('Guess_Glucose table:\\n',guess_glucose)\n",
    "print ('\\nAssigning glucose values to NAN age values in the dataset...')\n",
    "    \n",
    "for i in range(0, 3):\n",
    "    for j in range(0, 3):\n",
    "        diabetes2.loc[ (diabetes2.glucoseLevel.isnull()) & (diabetes2.Pedigree_cat == i) \\\n",
    "                    & (diabetes.BP_cat == j),'glucoseLevel'] = guess_glucose[i,j]\n",
    "                    \n",
    "\n",
    "diabetes2['glucoseLevel'] = diabetes2['glucoseLevel'].astype(int)\n",
    "print()\n",
    "diabetes2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The guess matrix for age as a dataframe is shown below:\n",
      "\n",
      "         BMI_cat        \n",
      "               0   1   2\n",
      "BP_cat 0      24  29  33\n",
      "       1      25  29  32\n",
      "       2      55  37  31\n",
      "The guess matrix for glucose as a dataframe is shown below:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">BP_cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Pedigree_cat</th>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>112</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>127</td>\n",
       "      <td>115</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>149</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               BP_cat          \n",
       "                    0    1    2\n",
       "Pedigree_cat 0    115  112  133\n",
       "             1    127  115  129\n",
       "             2    137  149  159"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_df = pd.DataFrame(guess_ages)\n",
    "\n",
    "columns = [(\"BMI_cat\",0),(\"BMI_cat\",1),(\"BMI_cat\",2)]\n",
    "age_df.columns = pd.MultiIndex.from_tuples(columns)\n",
    "\n",
    "index = [(\"BP_cat\",0),(\"BP_cat\",1),(\"BP_cat\",2)]\n",
    "age_df.index = pd.MultiIndex.from_tuples(index)\n",
    "print(\"The guess matrix for age as a dataframe is shown below:\\n\")\n",
    "print(age_df)\n",
    "\n",
    "\n",
    "glucose_df = pd.DataFrame(guess_glucose)\n",
    "\n",
    "columns2 = [(\"BP_cat\",0),(\"BP_cat\",1),(\"BP_cat\",2)]\n",
    "glucose_df.columns = pd.MultiIndex.from_tuples(columns2)\n",
    "\n",
    "index2 = [(\"Pedigree_cat\",0),(\"Pedigree_cat\",1),(\"Pedigree_cat\",2)]\n",
    "glucose_df.index = pd.MultiIndex.from_tuples(index2)\n",
    "print(\"The guess matrix for glucose as a dataframe is shown below:\\n\")\n",
    "glucose_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__5. Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 5 categories each.__\n",
    "\n",
    "__Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 20% test split. Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>IsDiabetic</th>\n",
       "      <th>BP_cat</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>Pedigree_cat</th>\n",
       "      <th>insulin_cat</th>\n",
       "      <th>glucoseLevel_cat</th>\n",
       "      <th>Age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  IsDiabetic  BP_cat  BMI_cat  Pedigree_cat  insulin_cat  \\\n",
       "0              6           1       1        1             0            0   \n",
       "1              1           0       1        1             0            0   \n",
       "2              8           1       1        1             0            0   \n",
       "3              1           0       1        1             0            0   \n",
       "4              0           1       0        1             2            0   \n",
       "\n",
       "   glucoseLevel_cat  Age_cat  \n",
       "0                 3        2  \n",
       "1                 2        0  \n",
       "2                 4        0  \n",
       "3                 2        0  \n",
       "4                 3        0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Converting glucose and age into categorical variables of 5 categories each\n",
    "X_glucose = pd.cut(diabetes2[\"glucoseLevel\"],bins=5,labels = [\"Lowest\", \"Lower\", \"Medium\", \"Higher\", \"Highest\"])\n",
    "X_glucose=X_glucose.map({'Lowest': 0, 'Lower': 1,'Medium' :2, 'Higher':3, 'Highest':4})\n",
    "diabetes2['glucoseLevel_cat'] = X_glucose\n",
    "\n",
    "X_age = pd.cut(diabetes2[\"Age\"],bins=5,labels = [\"Lowest\", \"Lower\", \"Medium\", \"Higher\", \"Highest\"])\n",
    "X_age=X_age.map({'Lowest': 0, 'Lower': 1,'Medium' :2, 'Higher':3, 'Highest':4})\n",
    "diabetes2['Age_cat'] = X_age\n",
    "\n",
    "\n",
    "diabetes2.drop(\"glucoseLevel\",axis=1, inplace=True)\n",
    "diabetes2.drop(\"BP\",axis=1, inplace=True)\n",
    "diabetes2.drop(\"insulin\",axis=1, inplace=True)\n",
    "diabetes2.drop(\"BMI\",axis=1, inplace=True)\n",
    "diabetes2.drop(\"Pedigree\",axis=1, inplace=True)\n",
    "diabetes2.drop(\"Age\",axis=1, inplace=True)\n",
    "\n",
    "diabetes2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TimesPregnant  BP_cat  BMI_cat  Pedigree_cat  insulin_cat  \\\n",
      "0              6       1        1             0            0   \n",
      "1              1       1        1             0            0   \n",
      "2              8       1        1             0            0   \n",
      "3              1       1        1             0            0   \n",
      "4              0       0        1             2            0   \n",
      "\n",
      "   glucoseLevel_cat  Age_cat  \n",
      "0                 3        2  \n",
      "1                 2        0  \n",
      "2                 4        0  \n",
      "3                 2        0  \n",
      "4                 3        0  \n",
      "\n",
      "\n",
      " 0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: IsDiabetic, dtype: int64\n",
      "Number of samples in training data: 614\n",
      "Number of samples in validation data: 154\n",
      "\n",
      " Use this dataset (with all features in categorical form) to train perceptron,\n",
      "logistic regression and random forest models using 20% test split. Report training and test accuracies..\n",
      "\n",
      " Training accuracy for logistic regression: 0.768729641694\n",
      "Test accuracy for logistic regression:  0.714285714286\n",
      "\n",
      " Training accuracy for perceptron: 0.711726384365\n",
      "Test accuracy for perceptron:  0.701298701299\n",
      "\n",
      " Training accuracy for Random Forest: 0.899022801303\n",
      "Test accuracy for Random Forest:  0.655844155844\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>IsDiabetic</th>\n",
       "      <th>BP_cat</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>Pedigree_cat</th>\n",
       "      <th>insulin_cat</th>\n",
       "      <th>glucoseLevel_cat</th>\n",
       "      <th>Age_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  IsDiabetic  BP_cat  BMI_cat  Pedigree_cat  insulin_cat  \\\n",
       "0              6           1       1        1             0            0   \n",
       "1              1           0       1        1             0            0   \n",
       "2              8           1       1        1             0            0   \n",
       "3              1           0       1        1             0            0   \n",
       "4              0           1       0        1             2            0   \n",
       "\n",
       "   glucoseLevel_cat  Age_cat  \n",
       "0                 3        2  \n",
       "1                 2        0  \n",
       "2                 4        0  \n",
       "3                 2        0  \n",
       "4                 3        0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying various ML methods\n",
    "\n",
    "# Getting features and response from the data as 2 separate dataframes\n",
    "X=diabetes2.loc[:,[\"TimesPregnant\",\"BP_cat\",\"BMI_cat\", \"Pedigree_cat\",\"insulin_cat\",\"glucoseLevel_cat\",\"Age_cat\"]]\n",
    "print(X.head())\n",
    "\n",
    "Y=diabetes2['IsDiabetic']\n",
    "print(\"\\n\\n\",Y.head())\n",
    "\n",
    "# Splitting the data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=100)\n",
    "print('Number of samples in training data:',len(x_train))\n",
    "print('Number of samples in validation data:',len(x_test))\n",
    "\n",
    "print('''\\n Use this dataset (with all features in categorical form) to train perceptron,\n",
    "logistic regression and random forest models using 20% test split. Report training and test accuracies..''')\n",
    "\n",
    "\n",
    "\n",
    "# Logistic regression\n",
    "logreg = LogisticRegression() \n",
    "logreg.fit(x_train, y_train) \n",
    "\n",
    "# Training accuracy\n",
    "training_accuracy_logistic=logreg.score(x_train,y_train)\n",
    "print ('\\n Training accuracy for logistic regression:',training_accuracy_logistic)\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy_logistic=logreg.score(x_test,y_test)\n",
    "print('Test accuracy for logistic regression: ', test_accuracy_logistic)\n",
    "\n",
    "\n",
    "# Perceptron\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "\n",
    "# Training accuracy\n",
    "training_accuracy_perceptron=perceptron.score(x_train,y_train)\n",
    "print ('\\n Training accuracy for perceptron:',training_accuracy_perceptron)\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy_perceptron=perceptron.score(x_test,y_test)\n",
    "print('Test accuracy for perceptron: ', test_accuracy_perceptron)\n",
    "\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=1000)\n",
    "random_forest.fit(x_train, y_train)\n",
    "\n",
    "# Training accuracy\n",
    "training_accuracy_rf=random_forest.score(x_train,y_train)\n",
    "print ('\\n Training accuracy for Random Forest:',training_accuracy_rf)\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy_rf=random_forest.score(x_test,y_test)\n",
    "print('Test accuracy for Random Forest: ', test_accuracy_rf)\n",
    "\n",
    "diabetes2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "1. __Derive the expression for the optimal parameters in the linear regression equation, i.e. solve the normal equation for Ordinary Least Squares for the case of Simple Linear Regression, when we only have one input and one output__\n",
    "\n",
    "Given a set of _n_ points $(X_i,Y_i)$ where $Yi$ is dependent on $Xi$ by a linear relation,  find the best-fit line,$$Z_i = {aX_i + b}$$  that minimizes the __sum of squared errors in Y__,i.e: $$minimize \\sum_{i}{(Y_i- Z_i)^2}$$\n",
    "__i. __ Show that $$ intercept \\quad b = \\overline{Y}-  a.\\overline{X}\\quad  and   \\quad slope \\quad a= \\frac{\\sum_{i}(X_i- \\overline{X})\u0001(Y_i- \\overline{Y})^2}{ \\sum_{i}(X_i- \\overline{X})}$$\n",
    "\n",
    "\n",
    " where $\\overline{X}$ and  $\\overline{Y}$ are the averages of the X values and the Y values, respectively.\n",
    " \n",
    "__ ii. __Show that slope _a_ can be written as $ a = r.(S_y /S_x)$ where $S_y$  = the standard deviation of the Y values and $S_x$= the standard deviation of the X values and _r_ is the correlation coefficient.\n",
    "\n",
    "##### Please try to write a nice LateXed version of your answer, and do the derivations of the expressions as nicely as possible\n",
    "\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "i. For least squares regression, the sum of the squares of the errors is minimized. Using calculus, we can find equations for the parameters a and b that minimize the sum of the squared errors, S.\n",
    "\n",
    "$\\min  S = \\displaystyle\\min \\sum\\limits_{i=1}^n \\left(e_i \\right)^2= \\min \\sum \\left(Y_i - Z_i \\right)^2= \\min \\sum \\left(Y_i - b - aX_i\\right)^2$\n",
    "\n",
    "We want to find b and a that minimize the sum, S. We start by taking the partial derivative of S with respect to b and setting it to zero: \n",
    "\n",
    "$\\displaystyle\\frac{\\partial{S}}{\\partial{b}} = -2 \\sum \\left(Y_i - b - aX_i\\right) = 0$\n",
    "\n",
    "$=>\\displaystyle\\sum \\left(Y_i - b - aX_i\\right) = 0$\n",
    "\n",
    "$=>\\displaystyle\\sum b = \\sum Y_i -a \\sum X_i$\n",
    "\n",
    "$=>\\displaystyle nb = \\sum Y_i -a\\sum X_i$\n",
    "\n",
    "$=>\\displaystyle b = \\frac{1}{n}\\sum Y_i - a \\frac{1}{n}\\sum X_i $ \n",
    "\n",
    "Let's call the above as equation 1\n",
    "\n",
    "$=>\\displaystyle b = \\bar Y - a . \\bar X  $\n",
    "\n",
    "where $\\bar Y$ and $\\bar X$ are the averages of the X values and Y values respectively. This completes the derivation of the\n",
    "intercept.\n",
    "\n",
    "Before taking partial derivative of S with respect to a, substitute the previous result for b in the equation for S\n",
    "\n",
    "$\\displaystyle \\min S = \\min \\sum \\left[Y_i-\\left(\\bar Y-a\\bar X \\right)-aX_i\\right]^{2}=\\min \\sum \\left[\\left(Y_i-\\bar Y\\right)-a\\left(X_i-\\bar X\\right)\\right]^{2}$\n",
    "\n",
    "Now, taking the partial derivative of S with respect to a and setting it to zero:\n",
    "\n",
    "$\\displaystyle \\frac{\\partial{S}}{\\partial{b}} = -2\\sum \\left[\\left(Y_i-\\bar Y\\right)-a\\left(X_i-\\bar X\\right)\\right]\\left(X_i-{\\bar X}\\right)=0$\n",
    "\n",
    "$=>\\displaystyle \\sum \\left(Y_i-\\bar Y\\right)\\left(X_i-\\bar X\\right)-a\\sum \\left(X_i-\\bar X\\right)^{2}=0$\n",
    "\n",
    "$=>\\displaystyle a = \\frac {\\sum \\left(X_i-\\bar X\\right)\\left(Y_i-\\bar Y\\right)}{\\sum \\left(X_i-\\bar X\\right)^{2}}$\n",
    "\n",
    "This completes the derivation of the slope.\n",
    "\n",
    "ii. We can divide the numerator and the denominator in the above equation obtained for slope by n to get the following equation:\n",
    "\n",
    "$=>\\displaystyle a = \\frac {\\sum \\left(X_i-\\bar X\\right)\\left(Y_i-\\bar Y\\right)}{\\sum \\left(X_i-\\bar X\\right)^{2}}$\n",
    "\n",
    "$=>\\displaystyle a = \\frac {\\operatorname {Cov} (X,Y)}{\\operatorname {Var} (X)}$\n",
    "\n",
    "We know that the covariance can be written as $ r . S_x . S_y$ , where r is the correlation coefficient and $S_x$ and $S_y$ are the standard deviation of X and Y values respectively. We also know that Var(X) = $(S_x)^2$. Substituting this in the above equation for the slope a, we get:\n",
    "\n",
    "$=>\\displaystyle a = \\frac {\\operatorname {Cov} (X,Y)}{\\operatorname {Var} (X)}$\n",
    "\n",
    "$=>\\displaystyle a = \\frac {r . S_x . S_y}{(S_x)^2}$\n",
    "\n",
    "$=>\\displaystyle a = \\frac {r.S_y}{S_x}$\n",
    "\n",
    "$=>\\displaystyle a = r.(S_y/S_x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Extra Credit Points: Fun with Webscraping & Text manipulation\n",
    "### (Mandatory for Grad students!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'> `NOTE:` **If you are a Graduate Section student (enrolled in 290), the Extra Credit Questions are mandatory.**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Statistics in Presidential Debates\n",
    "\n",
    "Your first task is to scrape Presidential Debates from the Commission of Presidential Debates website: http://www.debates.org/index.php?page=debate-transcripts.\n",
    "\n",
    "To do this, you are not allowed to manually look up the URLs that you need, instead you have to scrape them. The root url to be scraped is the one listed above, namely: http://www.presidency.ucsb.edu/debates.php\n",
    "\n",
    "\n",
    "1. By using `requests` and `BeautifulSoup` find all the links / URLs on the website that links to transcriptions of **First Presidential Debates** from the years [2012, 2008, 2004, 2000, 1996, 1988, 1984, 1976, 1960]. In total you should find 9 links / URLs tat fulfill this criteria.\n",
    "2. When you have a list of the URLs your task is to create a Data Frame with some statistics (see example of output below):\n",
    "    1. Scrape the title of each link and use that as the column name in your Data Frame. \n",
    "    2. Count how long the transcript of the debate is (as in the number of characters in transcription string). Feel free to include `\\` characters in your count, but remove any breakline characters, i.e. `\\n`. You will get credit if your count is +/- 10% from our result.\n",
    "    3. Count how many times the word **war** was used in the different debates. Note that you have to convert the text in a smart way (to not count the word **warranty** for example, but counting **war.**, **war!**, **war,** or **War** etc.\n",
    "    4. Also scrape the most common used word in the debate, and write how many times it was used. Note that you have to use the same strategy as in 3 in order to do this.\n",
    "    \n",
    "**Tips:**\n",
    "\n",
    "___\n",
    "\n",
    "In order to solve question 3 and 4 above it can be useful to work with Regular Expressions and explore methods on strings like `.strip(), .replace(), .find(), .count(), .lower()` etc. Both are very powerful tools to do string processing in Python. To count common words for example I used a `Counter` object and a Regular expression pattern for only words, see example:\n",
    "\n",
    "```python\n",
    "    from collections import Counter\n",
    "    import re\n",
    "\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", text.lower()))\n",
    "```\n",
    "\n",
    "Read more about Regular Expressions here: https://docs.python.org/3/howto/regex.html\n",
    "    \n",
    "    \n",
    "**Example output of all of the answers to EC Question 1:**\n",
    "\n",
    "\n",
    "![pres_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/president_stats.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4 as bs\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urls are:\n",
      " ['http://www.debates.org/index.php?page=october-3-2012-debate-transcript', 'http://www.debates.org/index.php?page=2008-debate-transcript', 'http://www.debates.org/index.php?page=september-30-2004-debate-transcript', 'http://www.debates.org/index.php?page=october-3-2000-transcript', 'http://www.debates.org/index.php?page=october-6-1996-debate-transcript', 'http://www.debates.org/index.php?page=september-25-1988-debate-transcript', 'http://www.debates.org/index.php?page=october-7-1984-debate-transcript', 'http://www.debates.org/index.php?page=september-23-1976-debate-transcript', 'http://www.debates.org/index.php?page=september-26-1960-debate-transcript']\n",
      "\n",
      "titles: \n",
      " ['October 3, 2012: The First Obama-Romney Presidential Debate', 'September 26, 2008: The First McCain-Obama Presidential Debate', 'September 30, 2004: The First Bush-Kerry Presidential Debate', 'October 3, 2000: The First Gore-Bush Presidential Debate', 'October 6, 1996: The First Clinton-Dole Presidential Debate', 'September 25, 1988: The First Bush-Dukakis Presidential Debate', 'October 7, 1984: The First Reagan-Mondale Presidential Debate', 'September 23, 1976: The First Carter-Ford Presidential Debate', 'September 26, 1960: The First Kennedy-Nixon Presidential Debate']\n"
     ]
    }
   ],
   "source": [
    "# PART A\n",
    "\n",
    "source = requests.get('http://www.debates.org/index.php?page=debate-transcripts').content\n",
    "soup = bs.BeautifulSoup(source,features='html.parser')\n",
    "#print(soup.prettify())\n",
    "#print(soup.a)\n",
    "soup.a.get('href')\n",
    "\n",
    "array = ['First', 'Presidential', 'Debate']\n",
    "url=[]\n",
    "title=[]\n",
    "links = soup.find_all('a')\n",
    "\n",
    "for l in links:\n",
    "    if all(x in l.text for x in array):\n",
    "        url.append(l.get('href'))\n",
    "        title.append(l.text)\n",
    "print('urls are:\\n',url)\n",
    "print('\\ntitles: \\n',title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>]\n"
     ]
    }
   ],
   "source": [
    "# PART 2A\n",
    "\n",
    "source=[]\n",
    "for i in range(len(url)):\n",
    "    source.append(requests.get(url[i]))\n",
    "print(source)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95108, 182428, 82726, 91071, 93095, 87736, 87000, 80837, 61013]\n",
      "[3, 44, 64, 11, 14, 8, 2, 7, 3]\n",
      "['the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']\n",
      "[757, 1470, 857, 919, 876, 804, 867, 857, 779]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>October 3, 2012: The First Obama-Romney Presidential Debate</th>\n",
       "      <th>September 26, 2008: The First McCain-Obama Presidential Debate</th>\n",
       "      <th>September 30, 2004: The First Bush-Kerry Presidential Debate</th>\n",
       "      <th>October 3, 2000: The First Gore-Bush Presidential Debate</th>\n",
       "      <th>October 6, 1996: The First Clinton-Dole Presidential Debate</th>\n",
       "      <th>September 25, 1988: The First Bush-Dukakis Presidential Debate</th>\n",
       "      <th>October 7, 1984: The First Reagan-Mondale Presidential Debate</th>\n",
       "      <th>September 23, 1976: The First Carter-Ford Presidential Debate</th>\n",
       "      <th>September 26, 1960: The First Kennedy-Nixon Presidential Debate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Debate char length</th>\n",
       "      <td>95108</td>\n",
       "      <td>182428</td>\n",
       "      <td>82726</td>\n",
       "      <td>91071</td>\n",
       "      <td>93095</td>\n",
       "      <td>87736</td>\n",
       "      <td>87000</td>\n",
       "      <td>80837</td>\n",
       "      <td>61013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war_count</th>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common_w</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common_w_count</th>\n",
       "      <td>757</td>\n",
       "      <td>1470</td>\n",
       "      <td>857</td>\n",
       "      <td>919</td>\n",
       "      <td>876</td>\n",
       "      <td>804</td>\n",
       "      <td>867</td>\n",
       "      <td>857</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    October 3, 2012: The First Obama-Romney Presidential Debate  \\\n",
       "Debate char length                                               95108            \n",
       "war_count                                                            3            \n",
       "most_common_w                                                      the            \n",
       "most_common_w_count                                                757            \n",
       "\n",
       "                    September 26, 2008: The First McCain-Obama Presidential Debate  \\\n",
       "Debate char length                                              182428               \n",
       "war_count                                                           44               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                               1470               \n",
       "\n",
       "                    September 30, 2004: The First Bush-Kerry Presidential Debate  \\\n",
       "Debate char length                                               82726             \n",
       "war_count                                                           64             \n",
       "most_common_w                                                      the             \n",
       "most_common_w_count                                                857             \n",
       "\n",
       "                    October 3, 2000: The First Gore-Bush Presidential Debate  \\\n",
       "Debate char length                                               91071         \n",
       "war_count                                                           11         \n",
       "most_common_w                                                      the         \n",
       "most_common_w_count                                                919         \n",
       "\n",
       "                    October 6, 1996: The First Clinton-Dole Presidential Debate  \\\n",
       "Debate char length                                               93095            \n",
       "war_count                                                           14            \n",
       "most_common_w                                                      the            \n",
       "most_common_w_count                                                876            \n",
       "\n",
       "                    September 25, 1988: The First Bush-Dukakis Presidential Debate  \\\n",
       "Debate char length                                               87736               \n",
       "war_count                                                            8               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                                804               \n",
       "\n",
       "                    October 7, 1984: The First Reagan-Mondale Presidential Debate  \\\n",
       "Debate char length                                               87000              \n",
       "war_count                                                            2              \n",
       "most_common_w                                                      the              \n",
       "most_common_w_count                                                867              \n",
       "\n",
       "                    September 23, 1976: The First Carter-Ford Presidential Debate  \\\n",
       "Debate char length                                               80837              \n",
       "war_count                                                            7              \n",
       "most_common_w                                                      the              \n",
       "most_common_w_count                                                857              \n",
       "\n",
       "                    September 26, 1960: The First Kennedy-Nixon Presidential Debate  \n",
       "Debate char length                                               61013               \n",
       "war_count                                                            3               \n",
       "most_common_w                                                      the               \n",
       "most_common_w_count                                                779               "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PART 2B\n",
    "\n",
    "soups = []\n",
    "content = []\n",
    "character_length = []\n",
    "war_count = []\n",
    "counts = []\n",
    "word = []\n",
    "frequency = []\n",
    "common_count = []\n",
    "common_word = []\n",
    "\n",
    "for i in range(len(url)):\n",
    "    soups.append(bs.BeautifulSoup(source[i].content, features='html.parser')) \n",
    "    #print(\"The transcript of\", title[i], \"debate is as follows\")\n",
    "    content.append(soups[i].find(id='content-sm').text)\n",
    "    #print(content[i])\n",
    "    character_length.append(len(content[i]))\n",
    "    # Part 2C counting the word war in the text\n",
    "    war_count.append(sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(\"war\"), content[i].lower())))\n",
    "    # Part 2D counting the most common word and its quantity\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", content[i].lower()))\n",
    "    word,frequency = counts.most_common(1)[0]\n",
    "    common_word.append(word)\n",
    "    common_count.append(frequency)\n",
    "    \n",
    "\n",
    "print(character_length)\n",
    "print(war_count)\n",
    "print(common_word)\n",
    "print(common_count)\n",
    "\n",
    "# making the final data frame\n",
    "indices = [\"Debate char length\",\"war_count\",\"most_common_w\",\"most_common_w_count\"]\n",
    "df_final = pd.DataFrame([character_length, war_count, common_word, common_count],columns=title,index=indices)\n",
    "df_final\n",
    "# number of years for reference\n",
    "#[2012, 2008, 2004, 2000, 1996, 1988, 1984, 1976, 1960]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 2. Download and read in specific line from many data sets\n",
    "\n",
    "Scrape the first 27 data sets from this URL http://people.sc.fsu.edu/~jburkardt/datasets/regression/ (i.e.`x01.txt` - `x27.txt`). Then, save the 5th line in each data set, this should be the name of the data set author (get rid of the `#` symbol, the white spaces and the comma at the end). \n",
    "\n",
    "Count how many times (with a Python function) each author is the reference for one of the 27 data sets. Showcase your results, sorted, with the most common author name first and how many times he appeared in data sets. Use a Pandas DataFrame to show your results, see example.\n",
    "\n",
    "**Example output of the answer EC Question 2:**\n",
    "\n",
    "![author_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/data_authors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n",
      "<class 'bs4.BeautifulSoup'>\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source2 = requests.get(\" http://people.sc.fsu.edu/~jburkardt/datasets/regression/ \") \n",
    "print(source2)\n",
    "\n",
    "soup2 = bs.BeautifulSoup(source2.content, features='html.parser') \n",
    "print(type(soup2))\n",
    "print(soup2.a)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of occurence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Helmut Spaeth</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S Chatterjee</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D G Kleinbaum and L L Kupper</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R J Freund and P D Minton</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S C Narula</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K A Brownlee</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S Chatterjee and B Price</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  # of occurence\n",
       "names                                           \n",
       "    Helmut Spaeth                             16\n",
       "    S Chatterjee                               3\n",
       "    D G Kleinbaum and L L Kupper               2\n",
       "    R J Freund and P D Minton                  2\n",
       "    S C Narula                                 2\n",
       "    K A Brownlee                               1\n",
       "    S Chatterjee and B Price                   1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KR code\n",
    "source3 = requests.get(\"http://people.sc.fsu.edu/~jburkardt/datasets/regression/\",) \n",
    "soup3 = bs.BeautifulSoup(source3.content, features='html.parser') \n",
    "print(source3) \n",
    "# If <Response [200]> then the website has been downloaded succesfully\n",
    "\n",
    "links3 = soup3.find('table').find_all('a')\n",
    "urls3 = ['http://people.sc.fsu.edu/~jburkardt/datasets/regression/'+l.get('href') for l in links3]\n",
    "urls3 = urls3[6:33]\n",
    "#urls3\n",
    "\n",
    "sourc = requests.get(urls3[15],) \n",
    "soup3 = bs.BeautifulSoup(sourc.content, features='html.parser') \n",
    "content3 = soup3.body\n",
    "#content3 = soup3.find('p').text\n",
    "chars3 = str(soup3)\n",
    "#chars3\n",
    "\n",
    "cnt = 0\n",
    "m=0\n",
    "names=[]\n",
    "while cnt<5: \n",
    "    if(chars3[m]=='\\n'):\n",
    "        cnt+=1\n",
    "    elif(cnt==4):\n",
    "        names.append(chars3[m])\n",
    "    m+=1\n",
    "\n",
    "#names\n",
    "\n",
    "names = ''.join(names)\n",
    "#names\n",
    "\n",
    "finallist=[]\n",
    "for i in range(len(urls3)):\n",
    "    lis=[]\n",
    "    sourc = requests.get(urls3[i],) \n",
    "    soup3 = bs.BeautifulSoup(sourc.content, features='html.parser') \n",
    "    content3 = soup3.body\n",
    "    chars3 = str(soup3)\n",
    "    cnt = 0\n",
    "    m=0\n",
    "    names=[]\n",
    "    while cnt<5: \n",
    "        if(chars3[m]=='\\n'):\n",
    "            cnt+=1\n",
    "        elif(cnt==4):\n",
    "            names.append(chars3[m])\n",
    "        m+=1\n",
    "    names = ''.join(names)\n",
    "    finallist.append(names)    \n",
    "    #chars = chars.replace('\\n', '')\n",
    "    #lis.append(len(chars))  #Adding total word count to the list first\n",
    "    #warcts = Counter(re.findall(r\"[ ][w][a][r][!?.,]? \", content.lower()))\n",
    "    #lis.append(len(list(warcts.elements()))) # Adding 'war' word count to the list\n",
    "    #counts = Counter(re.findall(r\"[\\w']+\", content.lower()))\n",
    "    #most_common,num_most_common = counts.most_common(1)[0]\n",
    "    #lis.append(most_common)    #Adding most common word\n",
    "    #lis.append(num_most_common)   #Adding most common word count\n",
    "    #finaldf[title[i]] = lis\n",
    "\n",
    "# finallist\n",
    "\n",
    "namesdf = pd.DataFrame(finallist)\n",
    "\n",
    "namesdf = namesdf.rename(columns = {0:'names'})\n",
    "\n",
    "# namesdf\n",
    "\n",
    "namesdf['names']=namesdf.names.str.extract('([A-Za-z ]+)')\n",
    "\n",
    "ans=  pd.DataFrame(namesdf.groupby('names')['names'].count())\n",
    "\n",
    "#ans.head()\n",
    "\n",
    "ans = ans.sort_values('names', ascending=0)\n",
    "ans = ans.rename(columns = {'names':'# of occurence'})\n",
    "\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
